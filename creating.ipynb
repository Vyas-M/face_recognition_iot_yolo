{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Studies and Applications\\Mini Project\\New face training thingy\\Og images\\Keshav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m out\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC:/Studies and Applications/Mini Project/test_yolo/Keshav/Keshav (\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(i)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m).jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m frame\u001b[39m=\u001b[39mcv\u001b[39m.\u001b[39mimread(path)\n\u001b[1;32m---> 16\u001b[0m classes, scores, boxes \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdetect(frame, Conf_threshold, NMS_threshold)\n\u001b[0;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m (classid, score, box) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(classes, scores, boxes):\n\u001b[0;32m     18\u001b[0m     color \u001b[39m=\u001b[39m COLORS[\u001b[39mint\u001b[39m(classid) \u001b[39m%\u001b[39m \u001b[39mlen\u001b[39m(COLORS)]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "Conf_threshold = 0.8\n",
    "NMS_threshold = 0.4\n",
    "COLORS = [(0, 255, 0), (0, 0, 255), (255, 0, 0),\n",
    "          (255, 255, 0), (255, 0, 255), (0, 255, 255)]\n",
    "class_name = []\n",
    "with open('C:/Studies and Applications/Mini Project/classes.txt', 'r') as f:\n",
    "    class_name = [cname.strip() for cname in f.readlines()]\n",
    "net = cv.dnn.readNet('C:/Studies and Applications/Mini Project/yolov4-tiny.weights', 'C:/Studies and Applications/Mini Project/yolov4-tiny.cfg')\n",
    "model = cv.dnn_DetectionModel(net)\n",
    "model.setInputParams(size=(416, 416), scale=1/255, swapRB=True)\n",
    "for i in range(1,76):\n",
    "    path=\"C:/Studies and Applications/Mini Project/Testnew/Keshav/Keshav (\"+str(i)+\").jpg\"\n",
    "    out=\"C:/Studies and Applications/Mini Project/test_yolo/Keshav/Keshav (\"+str(i)+\").jpg\"\n",
    "    frame=cv.imread(path)\n",
    "    classes, scores, boxes = model.detect(frame, Conf_threshold, NMS_threshold)\n",
    "    for (classid, score, box) in zip(classes, scores, boxes):\n",
    "        color = COLORS[int(classid) % len(COLORS)]\n",
    "        label = \"%s : %f\" % (class_name[classid], score)\n",
    "        cv.rectangle(frame, box, color, 1)\n",
    "        \n",
    "        if (class_name[classid]==\"person\"):\n",
    "            new_frame=frame[box[1]:box[3]+box[1],box[0]:box[2]+box[0]]\n",
    "            cv.imwrite(out,new_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 1280, 3)\n",
      "[0.9105592]\n",
      "inside....\n",
      "yess\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "Conf_threshold = 0.8\n",
    "NMS_threshold = 0.4\n",
    "COLORS = [(0, 255, 0), (0, 0, 255), (255, 0, 0),\n",
    "          (255, 255, 0), (255, 0, 255), (0, 255, 255)]\n",
    "class_name = []\n",
    "with open('C:/Studies and Applications/Mini Project/classes.txt', 'r') as f:\n",
    "    class_name = [cname.strip() for cname in f.readlines()]\n",
    "net = cv.dnn.readNet('C:/Studies and Applications/Mini Project/yolov4-tiny.weights', 'C:/Studies and Applications/Mini Project/yolov4-tiny.cfg')\n",
    "model = cv.dnn_DetectionModel(net)\n",
    "model.setInputParams(size=(416, 416), scale=1/255, swapRB=True)\n",
    "\n",
    "path=\"C:\\\\Studies and Applications\\\\Mini Project\\\\New face training thingy\\\\newfaces\\\\WIN_20230510_11_42_42_Pro.jpg\"\n",
    "out=\"C:\\\\Studies and Applications\\\\Mini Project\\\\New face training thingy\\\\newfaces\\\\Srivatsan_121.jpg\"\n",
    "frame=cv.imread(path)\n",
    "print(frame.shape)\n",
    "classes, scores, boxes = model.detect(frame, Conf_threshold, NMS_threshold)\n",
    "print(scores)\n",
    "for (classid, score, box) in zip(classes, scores, boxes):\n",
    "    print(\"inside....\")\n",
    "    color = COLORS[int(classid) % len(COLORS)]\n",
    "    label = \"%s : %f\" % (class_name[classid], score)\n",
    "    cv.rectangle(frame, box, color, 1)\n",
    "    if (class_name[classid]==\"person\"):\n",
    "        print(\"yess\")\n",
    "        new_frame=frame[box[1]:box[3]+box[1],box[0]:box[2]+box[0]]\n",
    "        cv.imwrite(out,new_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
